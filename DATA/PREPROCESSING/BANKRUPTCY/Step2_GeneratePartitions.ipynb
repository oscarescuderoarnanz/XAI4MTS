{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb28160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_tensor(df, y, eliminateColumn, columns, timeStepLength):\n",
    "    _, idx = np.unique(df.Admissiondboid, return_index=True)\n",
    "    listPatients = np.array(df.Admissiondboid)[np.sort(idx)]\n",
    "\n",
    "    index = df.index\n",
    "    y = y.reindex(index)\n",
    "\n",
    "    for i in range(len(listPatients)):\n",
    "        df_trial = df[df.Admissiondboid == listPatients[i]]\n",
    "        if eliminateColumn:\n",
    "            df_trial = df_trial.drop(columns=columns)\n",
    "        if i == 0:\n",
    "            X = np.array(df_trial)\n",
    "            X = X.reshape(1, timeStepLength, df.shape[1] - len(columns))\n",
    "        else:\n",
    "            X_2 = np.array(df_trial)\n",
    "            X_2 = X_2.reshape(1, timeStepLength, df.shape[1] - len(columns))\n",
    "            X = np.append(X, X_2, axis=0)\n",
    "    \n",
    "    #y = y.drop(['Admissiondboid'], axis=1)\n",
    "    keys = list(df_trial.keys())\n",
    "    \n",
    "    return X, y, keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c59b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################\n",
    "# # ROBUST NORM #\n",
    "# #########################\n",
    "\n",
    "def robustNorm(df, all_keys, binary_features):\n",
    "    \n",
    "    dicc_params = {}  # Dictionary to store min and max values for each column.\n",
    "\n",
    "    for id_key in range(len(all_keys)):\n",
    "        if not all_keys[id_key] in binary_features:\n",
    "            # Step 0: Remove all rows with the value 666.\n",
    "            values = df[all_keys[id_key]][df[all_keys[id_key]] != 666].values\n",
    "\n",
    "            # Step 1: Sort the values in ascending order.\n",
    "            values_sorted = sorted(values, reverse=False)\n",
    "\n",
    "            # Step 2: Determine 5% of the total values for trimming.\n",
    "            num_values = int(np.floor(len(values_sorted) * 0.05))\n",
    "\n",
    "            # Step 3: Discard the lowest and highest 5% of values.\n",
    "            min_value = values_sorted[num_values]\n",
    "            max_value = values_sorted[len(values_sorted) - num_values]\n",
    "            \n",
    "            # Store min and max values in the dictionary.\n",
    "            dicc_params[all_keys[id_key]] = [min_value, max_value]\n",
    "\n",
    "            # Step 4: Normalize values between min and max, saturating beyond limits.\n",
    "            for i in range(df.shape[0]):\n",
    "                val = df[all_keys[id_key]].iloc[i]\n",
    "                if val != 666:  # Skip the special value 666.\n",
    "                    if val <= min_value:\n",
    "                        df[all_keys[id_key]].iloc[i] = 0  # Saturate to 0.\n",
    "                    elif val >= max_value:\n",
    "                        df[all_keys[id_key]].iloc[i] = 1  # Saturate to 1.\n",
    "                    else:\n",
    "                        # Scale value between 0 and 1.\n",
    "                        df[all_keys[id_key]].iloc[i] = (df[all_keys[id_key]].iloc[i] * 1) / max_value\n",
    "\n",
    "    return df, dicc_params\n",
    "\n",
    "\n",
    "def apply_robustNorm(df, all_keys, binary_features, dicc_params):\n",
    "    \n",
    "    for id_key in range(len(all_keys)):\n",
    "        if not all_keys[id_key] in binary_features:\n",
    "            # Retrieve the min and max values from dicc_params.\n",
    "            arr = dicc_params[all_keys[id_key]]\n",
    "            min_value, max_value = arr[0], arr[1]\n",
    "\n",
    "            # Step 4: Normalize values between min and max, saturating beyond limits.\n",
    "            for i in range(df.shape[0]):\n",
    "                val = df[all_keys[id_key]].iloc[i]\n",
    "                if val != 666:  # Skip the special value 666.\n",
    "                    if val <= min_value:\n",
    "                        df[all_keys[id_key]].iloc[i] = 0  # Saturate to 0.\n",
    "                    elif val >= max_value:\n",
    "                        df[all_keys[id_key]].iloc[i] = 1  # Saturate to 1.\n",
    "                    else:\n",
    "                        # Scale value between 0 and 1.\n",
    "                        df[all_keys[id_key]].iloc[i] = (df[all_keys[id_key]].iloc[i] * 1) / max_value\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa9a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = ['year',\n",
    "           'Current_Assets', 'COGS', 'Depreciation_Amortization', 'EBITDA',\n",
    "           'Inventory', 'Net_Income', 'Receivables', 'Market_Value', 'Net_Sales',\n",
    "           'Total_Assets', 'Long-term_Debt', 'EBIT', 'Gross_Profit',\n",
    "           'Current_Liabilities', 'Retained_Earnings', 'Total_Revenue',\n",
    "           'Total_Liabilities', 'Operating_Expenses']\n",
    "\n",
    "binary_features = []\n",
    "\n",
    "print(\"Continuous variables:\", len(all_keys)-len(binary_features))\n",
    "print(\"Binary variables:\", len(binary_features))\n",
    "print(len(all_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101601c-b4e7-49ae-bde1-96b1d4b28349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "seeds = [395, 273, 159]\n",
    "folders = [\"s1\", \"s2\", \"s3\"]\n",
    "\n",
    "norm = \"robustNorm\"\n",
    "numberOfTimeStep = 10\n",
    "\n",
    "# Load the preprocessed data\n",
    "df_final_ir = pd.read_csv(\"bank_data_preprocessed.csv\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_final_ir = df_final_ir.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# Add a column to indicate if a patient (grouped by `Admissiondboid`) has any positive status (value of 1 in `individualMRGerm`)\n",
    "df_final_ir['is_positive'] = df_final_ir.groupby('Admissiondboid')['individualMRGerm'].transform(lambda x: 1 if (x == 1).any() else 0)\n",
    "\n",
    "\n",
    "df_final_aux = df_final_ir.copy()\n",
    "admissiondboid = df_final_aux['Admissiondboid'].unique()\n",
    "\n",
    "# Step 1: Identify positive and negative patients based on `is_positive`\n",
    "df_patients = df_final_aux.drop_duplicates(subset='Admissiondboid')\n",
    "\n",
    "# Separate positive and negative patients\n",
    "positive_patients = df_patients[df_patients['is_positive'] == 1]\n",
    "negative_patients = df_patients[df_patients['is_positive'] == 0]\n",
    "\n",
    "# Step 2: Balance patients at the patient level\n",
    "for i, folder in enumerate(folders):\n",
    "    print(f\"=========================================== {folder} ==================================\")\n",
    "    \n",
    "    \n",
    "    dev_data, test_data = train_test_split(df_patients, test_size=0.3, random_state=seeds[i], stratify=df_patients['is_positive'], shuffle=True)\n",
    "    \n",
    "    # Extract the test set data for all unique admissions in the test dataset\n",
    "    X_test = df_final_aux[df_final_aux.Admissiondboid.isin(test_data.Admissiondboid)].reset_index(drop=True)\n",
    "\n",
    "    # Perform undersampling to balance training data at the patient level\n",
    "    train_data = dev_data.copy()\n",
    "    positive_train = train_data[train_data['is_positive'] == 1]\n",
    "    negative_train = train_data[train_data['is_positive'] == 0]\n",
    "\n",
    "    # Calculate the desired number of negative patients for a 25/75 balance\n",
    "    desired_negative_count = int((len(positive_train) * 0.75 / 0.25))\n",
    "\n",
    "    # Perform undersampling on negative patients\n",
    "    negative_train_undersampled = resample(negative_train,\n",
    "                                           replace=False,\n",
    "                                           n_samples=desired_negative_count,\n",
    "                                           random_state=seeds[i])\n",
    "    \n",
    "    # Combine positive patients with the undersampled negative patients\n",
    "    balanced_train = pd.concat([positive_train, negative_train_undersampled])\n",
    "    \n",
    "    # Shuffle the training dataset\n",
    "    train_data = balanced_train.sample(frac=1, random_state=seeds[i]).reset_index(drop=True)\n",
    "    \n",
    "    # Initialize StratifiedKFold for 5-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seeds[i])\n",
    "    \n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(train_data, train_data['is_positive'])):\n",
    "        \n",
    "        train_split = train_data.iloc[train_index]\n",
    "        val_split = train_data.iloc[val_index]\n",
    "\n",
    "       \n",
    "        X_train = df_final_aux[df_final_aux.Admissiondboid.isin(train_split.Admissiondboid)].reset_index(drop=True)\n",
    "        X_val = df_final_aux[df_final_aux.Admissiondboid.isin(val_split.Admissiondboid)].reset_index(drop=True)\n",
    "\n",
    "       \n",
    "        X_test = df_final_aux[df_final_aux.Admissiondboid.isin(test_data.Admissiondboid)].reset_index(drop=True)\n",
    "\n",
    "        print(\"======>>>> Normalization type...... robustNorm <<<<<========\")\n",
    "      \n",
    "        X_train, parameters = robustNorm(X_train, all_keys, binary_features)\n",
    "        X_val = apply_robustNorm(X_val, all_keys, binary_features, parameters)\n",
    "        X_test = apply_robustNorm(X_test, all_keys, binary_features, parameters)\n",
    "\n",
    "\n",
    "        y_train = X_train[['Admissiondboid', 'dayToDone', 'individualMRGerm']]\n",
    "        y_val = X_val[['Admissiondboid', 'dayToDone', 'individualMRGerm']]\n",
    "        y_test = X_test[['Admissiondboid', 'dayToDone', 'individualMRGerm']]\n",
    "\n",
    "\n",
    "        X_train = X_train.drop([\"DaysOfStay\", \"DaysToPositive\", 'is_positive'], axis=1)\n",
    "        X_val = X_val.drop([\"DaysOfStay\", \"DaysToPositive\", 'is_positive'], axis=1)\n",
    "        X_test = X_test.drop([\"DaysOfStay\", \"DaysToPositive\", 'is_positive'], axis=1)\n",
    "\n",
    "        print(\"---\")\n",
    "        X_train_tensor, y_train_tensor, keys = dataframe_to_tensor(\n",
    "            X_train.copy(), X_train[[\"Admissiondboid\", \"dayToDone\", \"individualMRGerm\"]],\n",
    "            eliminateColumn=True, columns=['Admissiondboid', 'dayToDone', 'individualMRGerm'],\n",
    "            timeStepLength=numberOfTimeStep)\n",
    "\n",
    "        X_val_tensor, y_val_tensor, keys = dataframe_to_tensor(\n",
    "            X_val.copy(), X_val[[\"Admissiondboid\", \"dayToDone\", \"individualMRGerm\"]],\n",
    "            eliminateColumn=True, columns=['Admissiondboid', 'dayToDone', 'individualMRGerm'],\n",
    "            timeStepLength=numberOfTimeStep)\n",
    "\n",
    "        X_test_tensor, y_test_tensor, keys = dataframe_to_tensor(\n",
    "            X_test.copy(), X_test[[\"Admissiondboid\", \"dayToDone\", \"individualMRGerm\"]],\n",
    "            eliminateColumn=True, columns=['Admissiondboid', 'dayToDone', 'individualMRGerm'],\n",
    "            timeStepLength=numberOfTimeStep)\n",
    "\n",
    "\n",
    "        np.save(f\"../../BANK/{folder}/X_train_tensor_{fold}{norm}\", X_train_tensor)\n",
    "        y_train_tensor.to_csv(f\"../../BANK/{folder}/y_train_tensor_{fold}{norm}.csv\", index=False)\n",
    "\n",
    "        np.save(f\"../../BANK/{folder}/X_val_tensor_{fold}{norm}\", X_val_tensor)\n",
    "        y_val_tensor.to_csv(f\"../../BANK/{folder}/y_val_tensor_{fold}{norm}.csv\", index=False)\n",
    "\n",
    "        if fold == 0:  # Save the test set only once\n",
    "            np.save(f\"../../BANK/{folder}/X_test_tensor_{norm}\", X_test_tensor)\n",
    "            y_test_tensor.to_csv(f\"../../BANK/{folder}/y_test_tensor_{norm}.csv\", index=False)\n",
    "\n",
    "        # Save the keys\n",
    "        df = pd.DataFrame(keys, columns=['keys'])\n",
    "        df.to_csv(f\"../../BANK/{folder}/keys_{fold}{norm}.csv\", index=False)\n",
    "\n",
    "        print(f\"Fold {fold} completed for {folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e772be1-effe-499c-b986-be4403d59fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
